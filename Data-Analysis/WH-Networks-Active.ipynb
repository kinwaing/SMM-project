{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.algorithms.community import k_clique_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Retweet Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(fn):\n",
    "\n",
    "    json_data = []\n",
    "    \n",
    "    if type(fn) == str:\n",
    "        with open(fn,'rb') as f:\n",
    "            for line in f:\n",
    "                json_data.append(json.loads(line))\n",
    "    else:\n",
    "        for fn0 in fn:\n",
    "            with open(fn0,'rb') as f:\n",
    "                for line in f:\n",
    "                    json_data.append(json.loads(line))\n",
    "\n",
    "    return(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_chain = ''\n",
    "chain_json = load_json(path_to_chain)\n",
    "df_chain = pd.DataFrame(chain_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chain.rename(columns={'tweet_id_h':'nodeID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load White-Helmets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_df = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map records with correct parentID for retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Twitter data\n",
    "wh_df = wh_df.loc[wh_df['platform'] == 'twitter'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop dups\n",
    "wh_df_filt = wh_df.drop_duplicates('nodeID', keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get only action types retweets\n",
    "wh_df_rt = wh_df_filt.loc[wh_df_filt['actionType'] == 'retweet'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get correct retweet chain\n",
    "wh_df_rt = pd.merge(wh_df_rt, df_chain, on='nodeID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_df_rt = wh_df_rt.drop(columns=['parentID', 'rootID','tweet_postdate', 'tweeter_UTC_Offset', 'tweeter_followers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_df_rt.rename(columns={'retweeted_from_tweet_id_h':'parentID', 'source_tweet_id_h':'rootID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_wh_df_rt = wh_df.loc[wh_df['actionType'] != 'retweet'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_df_new = pd.concat([final_wh_df_rt, wh_df_rt], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get correct parentUserID for parentID field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ParentUserID - ParentID mapping\n",
    "wh_mapping = wh_df_new[['nodeID', 'nodeUserID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_mapping.rename(columns={'nodeID':'parentID', 'nodeUserID':'parentUserID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Include parent user ID for the retweet dataframe\n",
    "wh_df_rt = pd.merge(wh_mapping, wh_df_rt, on='parentID')\n",
    "wh_df_rt = wh_df_rt[['nodeID', 'nodeUserID', 'parentID', 'parentUserID', 'nodeTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### nodeTime to datetime object\n",
    "wh_df_rt['nodeTime'] = pd.to_datetime(wh_df_rt['nodeTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build retweet network\n",
    "rt_graph = wh_df_rt.groupby(['nodeUserID', 'parentUserID']).size().reset_index(name='weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build directed graph for retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create digraph for retweet diffusion\n",
    "g_nx = nx.from_pandas_edgelist(rt_graph,'parentUserID', 'nodeUserID', ['weight'], create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get largest strongly connected component\n",
    "lc_strong = sorted(nx.strongly_connected_components(g_nx), key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Subgraph of the largest connected component.\n",
    "rt_lc = g_nx.subgraph(lc_strong[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6376, 96316)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of nodes and edges in largest connected component\n",
    "rt_lc.number_of_nodes(), rt_lc.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get list of nodes in largest connected component\n",
    "rt_nodes = list(rt_lc.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get daily number of activities, and fill inactive days with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only activities for nodes in largest connected component\n",
    "rt_df = wh_df_rt.loc[wh_df_rt['nodeUserID'].isin(rt_nodes)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dailyTime field\n",
    "rt_df['dailyTime'] = rt_df['nodeTime'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#Compute daily activities of each node\n",
    "rt_df_daily_acts = rt_df.groupby(['nodeUserID','dailyTime']).size().reset_index(name='daily_acts')\n",
    "\n",
    "#dailyTime to datetime object\n",
    "rt_df_daily_acts['dailyTime'] = pd.to_datetime(rt_df_daily_acts['dailyTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_date =  max(rt_df_daily_acts['dailyTime'])\n",
    "min_date = min(rt_df_daily_acts['dailyTime'])\n",
    "\n",
    "idx = pd.date_range(min_date, max_date)\n",
    "rt_df_daily_acts.set_index('dailyTime', inplace=True)\n",
    "\n",
    "df_concat = []\n",
    "\n",
    "for user, group in rt_df_daily_acts.groupby('nodeUserID'):\n",
    "    s = group['daily_acts']\n",
    "    \n",
    "    s = s.reindex(idx, fill_value=0)\n",
    "   \n",
    "    df = pd.DataFrame(s)\n",
    "    df['nodeUserID'] = user\n",
    "    \n",
    "    df_concat.append(df)\n",
    "    \n",
    "rt_new_df = pd.concat(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_avg_df = rt_new_df.groupby('nodeUserID')['daily_acts'].mean().reset_index(name='avg_daily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_daily</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6376.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.106005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.283105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.007595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.081013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.303797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         avg_daily\n",
       "count  6376.000000\n",
       "mean      0.106005\n",
       "std       0.283105\n",
       "min       0.002532\n",
       "25%       0.007595\n",
       "50%       0.022785\n",
       "75%       0.081013\n",
       "max       5.303797"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_avg_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out users with an avg. number of activities less than the global avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_nodes = rt_avg_df.loc[rt_avg_df['avg_daily'] > 0.106005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rt_nodes_filter = list(rt_nodes['nodeUserID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only activities for nodes in largest connected component\n",
    "rt_df_filter = wh_df_rt.loc[wh_df_rt['nodeUserID'].isin(rt_nodes_filter)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build retweet network\n",
    "rt_graph_filter = rt_df_filter.groupby(['nodeUserID', 'parentUserID']).size().reset_index(name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create digraph for retweet diffusion\n",
    "g_nx_filter = nx.from_pandas_edgelist(rt_graph_filter,'parentUserID', 'nodeUserID', ['weight'], create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get largest strongly connected component\n",
    "lc_strong_filter = sorted(nx.strongly_connected_components(g_nx_filter), key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Subgraph of the largest connected component.\n",
    "rt_lc_filter = g_nx_filter.subgraph(lc_strong_filter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1247, 33655)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of nodes and edges in largest connected component\n",
    "rt_lc_filter.number_of_nodes(), rt_lc_filter.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_lc_filter_nodes = list(rt_lc_filter.nodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Only activities for users in filtered strongly connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_new_df_filter = rt_new_df.loc[rt_new_df['nodeUserID'].isin(rt_lc_filter_nodes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting to match DCRNN Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set dailyTime as a column in the df\n",
    "rt_new_df_filter.reset_index(level=0, inplace=True)\n",
    "rt_new_df_filter.rename(columns={'index':'nodeTime'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Build output files for DCRNN\n",
    "\n",
    "#Turn largest connected component subgraph into a dataframe\n",
    "rt_lc_df = nx.to_pandas_edgelist(rt_lc_filter)\n",
    "rt_lc_df['weight'] = 1\n",
    "#Find nodes with self-loops\n",
    "self_nodes = rt_lc_df.loc[rt_lc_df['source'] == rt_lc_df['target']]\n",
    "self_nodes = list(self_nodes['source'])\n",
    "\n",
    "nodes = list(set(rt_lc_filter_nodes) - set(self_nodes))\n",
    "\n",
    "#insert self-loops with weight 0 for records without self loops\n",
    "entries = [{'source':node, 'target':node, 'weight':0} for node in nodes]\n",
    "if len(entries) > 0:\n",
    "    rt_lc_df= rt_lc_df.append(entries)\n",
    "\n",
    "#encode the largest connected component into integers\n",
    "rt_lc_encoding = {}\n",
    "for _i, node in enumerate(rt_lc_filter_nodes):\n",
    "    rt_lc_encoding[node] = str(_i)\n",
    "rt_lc_df['source'] = rt_lc_df['source'].apply(lambda x: rt_lc_encoding[x])\n",
    "rt_lc_df['target'] = rt_lc_df['target'].apply(lambda x: rt_lc_encoding[x])\n",
    "\n",
    "#rename columns\n",
    "rt_lc_df.rename(columns={'source':'from', 'target':'to', 'weight':'distance'}, inplace=True)\n",
    "rt_lc_df['distance']= rt_lc_df['distance'].astype(float)\n",
    "#write id list to file\n",
    "with open('', 'w') as f:\n",
    "    f.write(\",\".join(list(rt_lc_encoding.values())))\n",
    "rt_lc_df.to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Features file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_new_df_filter['label'] = rt_new_df_filter['nodeUserID'].map(rt_lc_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_day_acts_formatted = rt_new_df_filter.pivot_table(values='daily_acts', index='nodeTime', columns='label', aggfunc='first')\n",
    "rt_day_acts_formatted.to_pickle('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_acts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.423467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.520660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.106329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.159494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.258228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.473418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.303797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          avg_acts\n",
       "count  1247.000000\n",
       "mean      0.423467\n",
       "std       0.520660\n",
       "min       0.106329\n",
       "25%       0.159494\n",
       "50%       0.258228\n",
       "75%       0.473418\n",
       "max       5.303797"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt_filter_avg.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pnnl_socialsim]",
   "language": "python",
   "name": "conda-env-pnnl_socialsim-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
